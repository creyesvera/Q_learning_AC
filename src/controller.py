# -*- coding: utf-8 -*-
"""controller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X2u83MNwZXUooXUvDJQOUSXRGx4X6fsV
"""

# Get the unique states from the 'state' column of df_features
unique_states = df_features['state'].unique()

# Initialize the Q-table with zeros for each unique state and action
initial_q_table = {
    state: [0.0 for _ in range(n_actions)]
    for state in unique_states
}

print(initial_q_table)


from IPython.display import display
import pandas as pd

# Convertir la Q-table a DataFrame
q_table_df = pd.DataFrame.from_dict(initial_q_table, orient='index')
q_table_df.columns = [f'Action {i}' for i in range(n_actions)]

# Mostrar en Colab
display(q_table_df)





rng = np.random.default_rng(seed=42)
env = ThermalEnv()

pi, q_table, q_tables_by_episode, rewards, td_errors_per_episode = q_learning_thermal(
    rng, env,
    n_episodes=10000,
    max_moves=10,
    initial_eps=1.0,
    final_eps=0.05,
    decay_rate=0.99,
    alpha=0.5,
    gamma=0.9,
    q_table=initial_q_table
)

all_actions = env.get_all_actions()

# Filtra solo los estados visitados
estados_visitados = sorted([s for s, c in estado_visitas.items() if c > 0])

# Visualiza
comparar_q_tables(q_tables_by_episode, all_actions)












# Recompensa acumulada
cumulative_rewards = np.cumsum(rewards)

# Recompensa promedio por episodio
average_rewards = np.cumsum(rewards) / (np.arange(len(rewards)) + 1)

# Gráfica de recompensa acumulada
plt.figure()
plt.plot(cumulative_rewards)
plt.title("Recompensa Acumulada por Episodio")
plt.xlabel("Episodio")
plt.ylabel("Recompensa Acumulada")
plt.grid(True)
plt.show()

# Gráfica de recompensa promedio
plt.figure()
plt.plot(average_rewards)
plt.title("Recompensa Promedio por Episodio")
plt.xlabel("Episodio")
plt.ylabel("Recompensa Promedio")
plt.grid(True)
plt.show()












plt.figure()
plt.plot(td_errors_per_episode)
plt.title("Error Temporal Difference por Episodio")
plt.xlabel("Episodio")
plt.ylabel("TD Error promedio")
plt.grid(True)
plt.show()















# Crear un diagrama de cajas del error TD por episodio
plt.figure()
plt.boxplot(td_errors_per_episode)
plt.title("Diagrama de Cajas del Error Temporal Difference por Episodio")
plt.xlabel("Episodio")  # En un boxplot, el eje X generalmente representa grupos o categorías
plt.ylabel("TD Error promedio")
plt.grid(True)
plt.show()



















import pandas as pd
import os

# Crear una carpeta para guardar las Q-tables si no existe
output_dir = "/content/drive/MyDrive/MachineLearning/q_tables_output"
import pandas as pd
import ipywidgets as widgets
from IPython.display import display

# Widget para seleccionar el número de episodio
episodio_selector = widgets.IntText(
    value=1,
    description='Episodio:',
    min=1
)

# Botones para mostrar o guardar la Q-table
boton_mostrar = widgets.Button(description="Mostrar Q-table")
boton_guardar = widgets.Button(description="Guardar como CSV")

# Función para mostrar la Q-table
def mostrar_q_table(b):
    episodio = episodio_selector.value
    if 1 <= episodio <= len(q_tables_by_episode):
        q_table = q_tables_by_episode[episodio - 1]
        q_df = pd.DataFrame.from_dict(q_table, orient='index', columns=[f'Action {j}' for j in range(n_actions)])
        display(q_df)
    else:
        print(f"❌ Episodio {episodio} no está en el rango disponible (1–{len(q_tables_by_episode)}).")

# Función para guardar la Q-table como CSV
def guardar_q_table(b):
    episodio = episodio_selector.value
    if 1 <= episodio <= len(q_tables_by_episode):
        q_table = q_tables_by_episode[episodio - 1]
        q_df = pd.DataFrame.from_dict(q_table, orient='index', columns=[f'Action {j}' for j in range(n_actions)])
        filename = f"{output_dir}/q_table_episode_{episodio}.csv"
        q_df.to_csv(filename)
        print(f"✅ Q-table del episodio {episodio} guardada como '{filename}'.")
    else:
        print(f"❌ Episodio {episodio} no está en el rango disponible (1–{len(q_tables_by_episode)}).")

# Asociar funciones a los botones
boton_mostrar.on_click(mostrar_q_table)
boton_guardar.on_click(guardar_q_table)

# Mostrar widgets
display(episodio_selector, boton_mostrar, boton_guardar)

















print("✅ Política aprendida (estado → acción óptima):\n")
for s, a in list(pi.items())[:20]:  # muestra solo los primeros 20
    print(f"{s} → {ACTIONS[a]}")













for s, a in pi.items():
    if s[1] == 0 and s[4] == 0:
        print(f"{s} → Acción aprendida: {ACTIONS[a]}")